model_type: encoder-only
max_seq_len: 1024
d_model: 512
n_layers: 6
n_heads: 16
drop_prob: 0.1
learnable_pos_emb: false
batch_size: 32
dl_num_workers: 32
threshold: 0.6
max_epochs: 300
model_path: 
pretrained_mlm_pt:  # Use None if you want to initialize weights randomly OR the path to the char-based BERT
device: 'cuda'